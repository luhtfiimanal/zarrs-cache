# ğŸš€ zarrs-cache

<div align="center">

**High-Performance Intelligent Caching for Scientific Computing**

*Enterprise-grade caching layer for zarrs with hybrid tiering, predictive warming, and advanced analytics*

[![Crates.io](https://img.shields.io/crates/v/zarrs-cache.svg)](https://crates.io/crates/zarrs-cache)
[![Documentation](https://docs.rs/zarrs-cache/badge.svg)](https://docs.rs/zarrs-cache)
[![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)](#license)
[![Build Status](https://img.shields.io/github/workflow/status/luthfiimanal/zarrs-cache/CI)](https://github.com/luthfiimanal/zarrs-cache/actions)

</div>

---

## âœ¨ Why zarrs-cache?

Scientific computing workloads often involve massive multidimensional arrays stored in cloud storage. **zarrs-cache** provides intelligent, high-performance caching that dramatically improves data access patterns for zarr arrays.

### ğŸ¯ **Perfect For:**
- ğŸ§¬ **Bioinformatics**: Genomic data analysis with predictable access patterns
- ğŸŒ **Climate Science**: Weather/climate model data with spatial locality
- ğŸ”¬ **Medical Imaging**: Large medical datasets with temporal access patterns
- ğŸ“Š **Data Analytics**: Any workload with large, chunked array data

### âš¡ **Performance That Matters**

| Cache Type | Latency | Throughput | Use Case |
|------------|---------|------------|----------|
| **Memory** | ~1-5Î¼s | 200K+ ops/sec | Hot data, real-time analysis |
| **Hybrid** | ~1-10Î¼s | 100K+ ops/sec | Intelligent tiering |
| **Disk** | ~100-500Î¼s | 2K+ ops/sec | Persistent, large datasets |

---

## ğŸ§  Intelligent Features

### ğŸ”„ **Hybrid Memory+Disk Tiering**
Automatically promotes frequently accessed data to memory and demotes cold data to disk.

```rust
use zarrs_cache::{HybridCache, HybridCacheConfig};
use std::time::Duration;

let config = HybridCacheConfig {
    memory_size: 512 * 1024 * 1024,  // 512MB fast memory
    disk_size: Some(10 * 1024 * 1024 * 1024), // 10GB persistent storage
    promotion_threshold: 0.1, // Promote after 0.1 accesses/second
    demotion_threshold: Duration::from_secs(300), // Demote after 5min inactivity
    ..Default::default()
};

let cache = HybridCache::new(config)?;
```

### ğŸ”¥ **Predictive Cache Warming**
Preloads data based on access patterns and spatial locality.

```rust
use zarrs_cache::{CacheWarmer, WarmingStrategy, PredictiveWarming};

let warmer = CacheWarmer::new(cache)
    .add_strategy(WarmingStrategy::Predictive(
        PredictiveWarming::new(10, 0.8) // Warm 10 keys with 80% confidence
    ));

// Automatically warm cache based on patterns
let warmed_count = warmer.warm(data_loader).await?;
println!("Warmed {} keys proactively", warmed_count);
```

### ğŸ“Š **Advanced Analytics & Monitoring**
Real-time performance insights with actionable recommendations.

```rust
use zarrs_cache::{MetricsCollector, MetricsConfig};

let metrics = MetricsCollector::new(MetricsConfig {
    track_access_patterns: true,
    track_efficiency: true,
    ..Default::default()
});

// Get comprehensive analytics
let report = metrics.generate_report(Duration::from_hours(1)).await;
println!("Hit rate: {:.1}%", report.performance_summary.average_hit_rate * 100.0);
println!("Spatial locality: {:.1}%", report.access_patterns.spatial_locality_score * 100.0);

// Automatic optimization recommendations
for rec in report.recommendations {
    println!("ğŸ’¡ {}: {}", rec.category, rec.description);
}
```

### âœ¨ **Core Features**
- ğŸš€ **LRU Memory Cache**: Lightning-fast in-memory caching with automatic eviction
- ğŸ’¾ **Disk Cache**: Persistent storage with TTL support and compression
- ğŸ”„ **Hybrid Tiering**: Intelligent promotion/demotion between memory and disk
- ğŸ—œï¸ **Compression**: Optional deflate compression to reduce storage overhead
- ğŸ”¥ **Cache Warming**: Predictive and neighbor-based preloading strategies
- ğŸ“Š **Advanced Metrics**: Comprehensive performance monitoring and analytics
- âš¡ **Async Support**: Full async/await support for non-blocking operations
- ğŸ”’ **Thread-Safe**: Safe for concurrent access across multiple threads

## Quick Start

Add this to your `Cargo.toml`:

```toml
[dependencies]
zarrs-cache = "0.1.0"
```

---

## ğŸš€ Quick Start

### Basic Memory Caching

```rust
use zarrs_cache::{LruMemoryCache, Cache};
use bytes::Bytes;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Create a 50MB memory cache
    let cache = LruMemoryCache::new(50 * 1024 * 1024);
    
    // Store scientific data
    let chunk_key = "temperature_field/chunk_100.200.50".to_string();
    let chunk_data = Bytes::from(vec![0u8; 8192]); // 8KB chunk
    
    cache.set(&chunk_key, chunk_data.clone()).await?;
    
    // Lightning-fast retrieval
    let start = std::time::Instant::now();
    if let Some(data) = cache.get(&chunk_key).await {
        println!("ğŸš€ Retrieved {}B in {:?}", data.len(), start.elapsed());
    }
    
    // Check performance stats
    let stats = cache.stats();
    println!("ğŸ“Š Hit rate: {:.1}%", 
        stats.hits as f64 / (stats.hits + stats.misses) as f64 * 100.0);
    
    Ok(())
}
```

### Production-Ready Setup

```rust
use zarrs_cache::{CachedStore, HybridCache, HybridCacheConfig, CacheConfig};
use tempfile::TempDir;
use std::time::Duration;

// Configure for production workload
let temp_dir = TempDir::new()?;
let cache_config = HybridCacheConfig {
    memory_size: 2 * 1024 * 1024 * 1024,  // 2GB memory
    disk_size: Some(100 * 1024 * 1024 * 1024), // 100GB disk
    disk_dir: temp_dir.path().to_path_buf(),
    promotion_threshold: 0.05, // Aggressive promotion
    demotion_threshold: Duration::from_secs(1800), // 30min timeout
    maintenance_interval: Duration::from_secs(60), // 1min maintenance
    ..Default::default()
};

let cache = HybridCache::new(cache_config)?;
let cached_store = CachedStore::new(
    your_storage_backend, 
    cache, 
    CacheConfig::default()
);

// Now your storage operations are automatically cached!
let data = cached_store.get_cached("my_array/chunk_0.0.0").await;
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    zarrs-cache Architecture                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ”¥ Cache Warming    â”‚  ğŸ“Š Analytics      â”‚  âš™ï¸ Management   â”‚
â”‚  â€¢ Predictive       â”‚  â€¢ Access Patterns â”‚  â€¢ Auto-tuning   â”‚
â”‚  â€¢ Neighbor-based   â”‚  â€¢ Performance     â”‚  â€¢ Maintenance    â”‚
â”‚  â€¢ Time-aware       â”‚  â€¢ Recommendations â”‚  â€¢ Monitoring     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    ğŸ§  Hybrid Cache Layer                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   ğŸ’¾ Memory     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚      ğŸ’¿ Disk Cache      â”‚â”‚
â”‚  â”‚   â€¢ LRU Cache   â”‚  Intelligent â”‚   â€¢ Persistent Store   â”‚â”‚
â”‚  â”‚   â€¢ ~1-5Î¼s      â”‚   Promotion  â”‚   â€¢ ~100-500Î¼s         â”‚â”‚
â”‚  â”‚   â€¢ Hot Data    â”‚   & Demotion â”‚   â€¢ Cold Data          â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      ğŸ—œï¸ Compression Layer                    â”‚
â”‚              â€¢ Deflate  â€¢ Transparent  â€¢ Configurable       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     ğŸ”Œ Storage Interface                     â”‚
â”‚           â€¢ S3  â€¢ Local FS  â€¢ HTTP  â€¢ Custom Backends       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ§© **Core Components**

| Component | Purpose | Key Features |
|-----------|---------|--------------|
| **ğŸ”Œ Cache Trait** | Generic caching interface | Async, thread-safe, extensible |
| **ğŸ’¾ LruMemoryCache** | Lightning-fast memory cache | LRU eviction, TTL support |
| **ğŸ’¿ DiskCache** | Persistent storage cache | File-based, compression, TTL |
| **ğŸ§  HybridCache** | Intelligent tiering | Auto promotion/demotion |
| **ğŸª CachedStore** | Storage wrapper | Transparent caching layer |
| **ğŸ“Š MetricsCollector** | Performance monitoring | Real-time analytics |

### Cache Strategy

The library implements intelligent caching that:
- Caches chunk data (e.g., `array/0.0.0`) for fast access
- Selectively caches metadata files (`.zarray`, `.zattrs`)
- Skips caching of group metadata (`.zgroup`) to avoid unnecessary memory usage

## API Reference

### CachedStore

```rust
impl<S, C> CachedStore<S, C> {
    pub fn new(store: S, cache: C, config: CacheConfig) -> Self
    pub async fn get_cached(&self, key: &str) -> Option<Bytes>
    pub async fn set_cached(&self, key: &str, value: Bytes) -> Result<(), CacheError>
    pub async fn remove_cached(&self, key: &str) -> Result<(), CacheError>
    pub async fn clear_cache(&self) -> Result<(), CacheError>
    pub fn cache_stats(&self) -> CacheStats
}
```

### LruMemoryCache

```rust
impl LruMemoryCache {
    pub fn new(max_size_bytes: usize) -> Self
}
```

### Cache Trait

```rust
#[async_trait::async_trait]
pub trait Cache: Send + Sync + 'static {
    async fn get(&self, key: &StoreKey) -> Option<Bytes>;
    async fn set(&self, key: &StoreKey, value: Bytes) -> Result<(), CacheError>;
    async fn remove(&self, key: &StoreKey) -> Result<(), CacheError>;
    async fn clear(&self) -> Result<(), CacheError>;
    fn size(&self) -> usize;
    fn stats(&self) -> CacheStats;
}
```

## Performance

The cache is designed for high performance with:
- **Cache hit latency**: < 1ms for memory cache
- **Memory efficiency**: > 90% useful data vs metadata overhead
- **Thread-safe operations**: Lock-free atomic operations where possible
- **Automatic eviction**: LRU-based eviction when cache size limits are reached

## Testing

Run the test suite:

```bash
cargo test
```

Run benchmarks:

```bash
cargo bench
```

Run the basic example:

```bash
cargo run --example basic_usage
```

## Configuration

### CacheConfig

```rust
pub struct CacheConfig {
    pub max_memory_size: usize,           // Maximum memory cache size in bytes
    pub disk_cache_dir: Option<PathBuf>,  // Optional disk cache directory
    pub max_disk_size: Option<u64>,       // Maximum disk cache size in bytes
    pub ttl: Option<Duration>,            // Time-to-live for cached entries
    pub enable_compression: bool,         // Enable compression for cached data
    pub prefetch_config: Option<PrefetchConfig>, // Prefetch strategy configuration
}
```

## Future Enhancements

- **Disk-based caching**: Persistent cache storage
- **Hybrid caching**: Memory + disk cache combination
- **Compression**: Optional data compression for cache entries
- **TTL support**: Time-based cache expiration

## ğŸ“„ License

Licensed under the **MIT License** ([LICENSE](LICENSE) or http://opensource.org/licenses/MIT).

This permissive license allows you to use zarrs-cache in both open source and proprietary software projects.
